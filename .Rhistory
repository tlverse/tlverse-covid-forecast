data[, case_days:=cumsum(cases>0), by=list(country)]
data[country=="USA"]
data[country=="United States"]
data$country
unique(data$country)
data[country=="US"]
#TODO: add in features
data[, region:=paste(country, state)]
data[, case_days:=cumsum(cases>0), by=list(region)]
data[region=="US California"]
ggplot(data[region=="US California"], aes(x=case_days, y=cases))+geom_line()
library(ggplot2)
ggplot(data[region=="US California"], aes(x=case_days, y=cases))+geom_line()
ggplot(data, aes(x=case_days, y=cases, group="region"))+geom_line()
ggplot(data, aes(x=case_days, y=cases, group="region"))+geom_line()+theme_bw()
data[cases>6e4]
ggplot(data, aes(x=case_days, y=cases, group=region))+geom_line()+theme_bw()
dim(data)
quantile(data$cases)
data[, first_case_date:=date[which.min(cases>0)], by=list(region)]
data[, case_days:=as.numeric(difftime(first_case_date, date,unit="days"))]
data[region=="US California"]
data[, case_days:=as.numeric(difftime(date, first_case_date,unit="days"))]
data[, case_days:=as.numeric(difftime(first_case_date, date,unit="days"))]
data[, tenth_case_date:=date[which.min(cases>10)], by=list(region)]
data[, first_case_date:=min(date[cases>0]), by=list(region)]
warnings()
data[, case_days:=as.numeric(difftime(date, first_case_date,unit="days"))]
data[, tenth_case_date:=min(date[cases>10]), by=list(region)]
data[, case10_days:=as.numeric(difftime(date, tenth_case_date,unit="days")), by=list(region)]
ggplot(data, aes(x=case_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case_days>0], aes(x=case_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case_days>0], aes(x=case10_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case10_days>0], aes(x=case10_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case_days>0], aes(x=case_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case10_days>0], aes(x=case10_days, y=cases, group=region))+geom_line()+theme_bw()
data[, hundreth_case_date:=min(date[cases>100]), by=list(region)]
data[, case100_days:=as.numeric(difftime(date, tenth_case_date,unit="days")), by=list(region)]
data[, case100_days:=as.numeric(difftime(date, hundreth_case_date,unit="days")), by=list(region)]
ggplot(data[case100_days>0], aes(x=case100_days, y=cases, group=region))+geom_line()+theme_bw()
covariates <- c("case_days")
data[, log_case_days:=ifelse(case_days>0, log10(case_days), 0)]
data[is.nan(log_case_days)]
covariates <- c("case_days","log_case_days")
make_sl3_Task(main_data, outcome="ConfirmedCases", covariates = covariates)
make_sl3_Task(main_data, outcome="cases", covariates = covariates)
lrnr_glm <- make_learner(Lrnr_glm)
make_sl3_Task(main_data, outcome="cases", covariates = covariates, id=region)
make_sl3_Task(main_data, outcome="cases", covariates = covariates, id="region")
lrnr_rf <- make_learner(Lrnr_randomForest)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf))
return(sl)
#TODO: carefully consider fold structure
task <- make_sl3_Task(main_data, outcome="cases", covariates = covariates, id="region")
fit <- sl$train(task)
fit
loss_squared_error()
loss_squared_error
metalearner_competition <- make_learner(Lrnr_solnp, loss_competition, metalearner_linear)
load_all("tlversecovidforecast")
metalearner_competition <- make_learner(Lrnr_solnp, loss_competition, metalearner_linear)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
load_al("tlversecovidforecast/")
load_all("tlversecovidforecast/")
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
load_all("tlversecovidforecast/")
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
fit
fit$predict()
plot(task$Y, fit$predict())
cv_preds <- fit$predict_fold(task, "validation")
risk <- mean(loss_competition(cv_preds, task$Y))
risk
rmse <- sqrt(mean(loss_competition(cv_preds, task$Y)))
rmse
loss_competition(cv_preds, task$Y)
table(data$region)
main_data <- fread("Data/covid19-global-forecasting-week-1/train.csv")
View(main-data)
View(main_data)
main_data <- fread("Data/covid19-global-forecasting-week-1/train.csv")
old_names <- c("Id", "Province/State", "Country/Region", "Lat", "Long", "Date",
"ConfirmedCases", "Fatalities")
new_names <- c("id","state", "country", "lat", "long", "date", "cases", "deaths")
setnames(main_data, old_names, new_names)
data <- main_data
#TODO: add in features
data[, region:=paste(country, state)]
data[, first_case_date:=min(date[cases>0]), by=list(region)]
data[, case_days:=as.numeric(difftime(date, first_case_date,unit="days"))]
data[, log_case_days:=ifelse(case_days>0, log10(case_days), 0)]
data[, tenth_case_date:=min(date[cases>10]), by=list(region)]
data[, case10_days:=as.numeric(difftime(date, tenth_case_date,unit="days")), by=list(region)]
data[, hundreth_case_date:=min(date[cases>100]), by=list(region)]
data[, case100_days:=as.numeric(difftime(date, hundreth_case_date,unit="days")), by=list(region)]
table(data$region)
ggplot(data[case_days>0], aes(x=case_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case100_days>0], aes(x=case100_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case10_days>0], aes(x=case10_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case100_days>0], aes(x=case100_days, y=cases, group=region))+geom_line()+theme_bw()
data[, max_cases:=max(cases), by=list(region)]
ggplot(data[case100_days>0&max_cases>200], aes(x=case100_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case10_days>0&max_cases>200], aes(x=case10_days, y=cases, group=region))+geom_line()+theme_bw()
ggplot(data[case100_days>0&max_cases>200], aes(x=case100_days, y=log(cases), group=region))+geom_line()+theme_bw()
ggplot(data[case_days>0], aes(x=case_days, y=log(cases), group=region))+geom_line()+theme_bw()
ggplot(data[case100_days>0&max_cases>200], aes(x=case100_days, y=log(cases), group=region))+geom_line()+theme_bw()
ggplot(data[case100_days>0&max_cases>200&country=="China"], aes(x=case100_days, y=log(cases), group=region))+geom_line()+theme_bw()
metalearner_linear
load_all("tlversecovidforecast/")
load_all("tlversecovidforecast/")
load_all("tlversecovidforecast/")
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear_bound, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
load_all("tlversecovidforecast/")
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear_bound, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
load_all("tlversecovidforecast/")
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear_bound, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
fit
rmse <- sqrt(mean(loss_competition(cv_preds, task$Y)))
rmse
mean(loss_competition(cv_preds, task$Y)
)
quantile(loss_competition(cv_preds, task$Y)
)
setwd("~/Dropbox/t6/t6r/")
library(devtools)
load_all()
database_list <- get_database_list()
database_list <- database_list[enabled==TRUE]
row <- 1
database <- database_list[row]
View(database_list)
database <- database_list[row]
message(database$hospital)
do_updates(database)
load_all()
database <- database_list[row]
message(database$hospital)
load_all()
patient_data[field_name=="InjuryTime"]
load_all()
database <- database_list[row]
message(database$hospital)
do_updates(database)
load_all()
database <- database_list[row]
message(database$hospital)
do_updates(database)
# trauma time
tt_arrival <- patient_data[field_name=="ArrivalTime",list(analytics_id, arrival_time=field_value)]
tt_injury <- patient_data[field_name=="InjuryTime",list(analytics_id, injury_time=field_value)]
tt2 <- merge(tt_injury, tt_arrival)
tt[,transit_time := parse_time_col(arrival_time) - parse_time_col(injury_time)]
tt2[,transit_time := parse_time_col(arrival_time) - parse_time_col(injury_time)]
transit_time <- tt2[,list(analytics_id,
characteristic="Time in transit",
value=as.numeric(transit_time))]
load_all()
do_updates(database)
tt2
tt2[,transit_time := difftime(parse_time_col(injury_time), parse_time_col(arrival_time), units="minutes"]
transit_time <- tt2[,list(analytics_id,
characteristic="Time in transit",
value=as.numeric(transit_time))]
# a+ url
# TODO: use reimplement when Hubert changes A+
# analytics_ids <- unique(patient_data$analytics_id)
# aplus_url <- data.table(analytics_id = analytics_ids,
#                         characteristic = "View patient on A+",
#                         value=get_aplus_urls(db, analytics_ids))
mrns <- patient_data[grepl("mrn",field_name, ignore.case=TRUE)]
demo_patients <- get_demo_patients()
is_demo_patient <- patient_data[,list(characteristic="Demo patient",
value=analytics_id[1]%in%demo_patients),
by=list(analytics_id)]
fields_completed <- patient_data[,list(characteristic="Fields completed",
value=.N), by=list(analytics_id)]
complex_characteristics <- rbindlist(list(gps_coords, date, age_group, mortality,
arrival_time, trauma_time, transit_time,
is_demo_patient, fields_completed),
fill=TRUE)
characteristics <- rbind(simple_characteristics, complex_characteristics)
# add missing characteristics
all_characteristics <- pc_metadata$characteristic
all_analytics_id <- unique(patient_data$analytics_id)
all_pc <- as.data.table(expand.grid(analytics_id=all_analytics_id, characteristic=all_characteristics))
characteristics <- merge(all_pc, characteristics, all.x = TRUE, by=c("analytics_id","characteristic"))
# characteristics[is.na(value),value:="Data not entered"]
# expand_chars_wide <- function(char_data){
#   expanded <- expand.grid(tapply(char_data$value,char_data$characteristic,list),stringsAsFactors = FALSE)
#   full <- data.table(matrix(NA_character_, nrow=nrow(expanded),ncol=length(all_characteristic_fields)))
#   names(full) <- all_characteristic_fields
#   set(full,,names(expanded),expanded)
#
#   return(full)
# }
# characteristics_wide <- characteristics[,expand_chars_wide(.SD),by=list(analytics_id)]
return(characteristics)
}
#' @export
#' @export
update_patient_characteristics <- function(database, patient_data){
pc <- patient_characteristics(database, patient_data)
# TODO: overwrite or append depends on if this is a RCTW or an incremental update
write_table(database$analytics_dsn, "patient_characteristics",pc, overwrite=FALSE, append=TRUE)
}
tt2[,transit_time := difftime(parse_time_col(injury_time), parse_time_col(arrival_time), units="minutes")]
tt2[,transit_time := difftime(parse_time_col(injury_time), parse_time_col(arrival_time), units="mins")]
tt2
tt2[,transit_time := difftime(parse_time_col(arrival_time), parse_time_col(injury_time), units="mins")]
tt2
load_all()
library(t6r)
library(foreach)
# load_all()
# t6_source_database("~/t6_test_anon.dsn")
# t6_analytics_database("~/t6_analytics.dsn")
database_list <- get_database_list()
database_list <- database_list[enabled==TRUE]
row <- 1
database <- database_list[row]
database <- database_list[row]
message(database$hospital)
do_updates(database)
database
database_list
row <- 3
database <- database_list[row]
database <- database_list[row]
message(database$hospital)
do_updates(database)
row <- 4
database <- database_list[row]
database <- database_list[row]
message(database$hospital)
do_updates(database)
row <- 1
database <- database_list[row]
database
# grab real data to sample from
patients <- run_query(database$analytics_dsn,
sprintf("SELECT distinct analytics_id from
V_PATIENT_GUIDELINE_ACTIVITY
WHERE LOCATION='%s'
AND PATIENT is not null
AND GUIDELINE_NAME is not null",
database$hospital))
cpg_metadata <- get_cpg_metadata(database)
parsed_df <- parse_metadata(cpg_metadata)
# for each date:
synth_dates <- seq(from = as.POSIXct("2019-09-01"),
to = as.POSIXct("2020-03-24"),
by = "1 day")
synth_dates <- unique(floor_date(synth_dates, unit = "days"))
synth_date <- as.POSIXct("2019-06-02")
for(synth_date in synth_dates){
synth_date <- as.POSIXct(synth_date, origin = "1970-01-01")
print(synth_date)
n_patients <- round(runif(1, 8, 12))
for(i in seq_len(n_patients)){
print(i)
try({
generate_synth_patient(synth_date, patients, cpg_metadata, parsed_df)
})
}
}
# for each date:
synth_dates <- seq(from = as.POSIXct("2019-09-25"),
to = as.POSIXct("2020-03-24"),
by = "1 day")
synth_dates <- unique(floor_date(synth_dates, unit = "days"))
synth_date <- as.POSIXct("2019-06-02")
for(synth_date in synth_dates){
synth_date <- as.POSIXct(synth_date, origin = "1970-01-01")
print(synth_date)
n_patients <- round(runif(1, 8, 12))
for(i in seq_len(n_patients)){
print(i)
try({
generate_synth_patient(synth_date, patients, cpg_metadata, parsed_df)
})
}
}
setwd("~/Dropbox/tlverse/tlverse-covid-forecast/")
load_all("tlversecovidforecast/")
install_github("tlverse/origami@devel")
main_data <- fread("Data/covid19-global-forecasting-week-1/train.csv")
old_names <- c("Id", "Province/State", "Country/Region", "Lat", "Long", "Date",
"ConfirmedCases", "Fatalities")
new_names <- c("id","state", "country", "lat", "long", "date", "cases", "deaths")
setnames(main_data, old_names, new_names)
main_data$date <- as.Date(main_data$date)
###TODO: merge in helper datasets
#1. Add intervention data (school, restrictions,quarantine)
#2. Add population, density, urban population, median age, sex info
#3. Add test and test population
#4. Add percent smokers and lung disease info
restrictions_data <- fread("Data/covid19-global-forecasting-week-1/restrictions_info_data.csv")
main_data$date <- as.Date(main_data$date)
restrictions_data$schools_national_date <- as.Date(restrictions_data$schools_national_date)
restrictions_data$schools_localized_date <- as.Date(restrictions_data$schools_localized_date)
restrictions_data$restrictions_date <- as.Date(restrictions_data$restrictions_date)
restrictions_data$quarantine_date <- as.Date(restrictions_data$quarantine_date)
main_data <- merge(main_data, restrictions_data[,c("country","population","tests","testpop","density",
"median_age","urbanpop","smokers", "sex_ratio",
"quarantine_date","restrictions_date",
"schools_national_date","schools_localized_date",
"hospital_bed","lung_disease")], by = c("country"), all.x = TRUE)
main_data <- main_data %>%
group_by(country) %>%
mutate(intervention_school_national = ifelse(date < schools_national_date,0,1)) %>%
mutate(intervention_school_local = ifelse(date < schools_localized_date,0,1)) %>%
mutate(intervention_restriction = ifelse(date < restrictions_date,0,1)) %>%
mutate(intervention_quarantine = ifelse(date < quarantine_date,0,1)) %>%
select(-c(schools_national_date,schools_localized_date,restrictions_date,quarantine_date))
data <- main_data
#TODO: add in features
data[, region:=paste(country, state)]
data[, first_case_date:=min(date[cases>0]), by=list(region)]
data[, case_days:=as.numeric(difftime(date, first_case_date,unit="days"))]
data[, log_case_days:=ifelse(case_days>0, log10(case_days), 0)]
data[, tenth_case_date:=min(date[cases>10]), by=list(region)]
data[, case10_days:=as.numeric(difftime(date, tenth_case_date,unit="days")), by=list(region)]
data[, hundreth_case_date:=min(date[cases>100]), by=list(region)]
data[, case100_days:=as.numeric(difftime(date, hundreth_case_date,unit="days")), by=list(region)]
data[, max_cases:=max(cases), by=list(region)]
covars <- colnames(main_data)[-which(names(main_data) %in% c("cases","region"))]
covars <- colnames(data)[-which(names(data) %in% c("cases","region"))]
folds <- origami::make_folds(data, t = max(data$time), id = data$region,
time = data$time,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
library(origami)
document("tlversecovidforecast/")
library(devtools)
document("tlversecovidforecast/")
document("tlversecovidforecast/")
main_data <- fread("Data/covid19-global-forecasting-week-1/train.csv")
old_names <- c("Id", "Province/State", "Country/Region", "Lat", "Long", "Date",
"ConfirmedCases", "Fatalities")
new_names <- c("id","state", "country", "lat", "long", "date", "cases", "deaths")
setnames(main_data, old_names, new_names)
main_data$date <- as.Date(main_data$date)
###TODO: merge in helper datasets
#1. Add intervention data (school, restrictions,quarantine)
#2. Add population, density, urban population, median age, sex info
#3. Add test and test population
#4. Add percent smokers and lung disease info
restrictions_data <- fread("Data/covid19-global-forecasting-week-1/restrictions_info_data.csv")
main_data$date <- as.Date(main_data$date)
restrictions_data$schools_national_date <- as.Date(restrictions_data$schools_national_date)
restrictions_data$schools_localized_date <- as.Date(restrictions_data$schools_localized_date)
restrictions_data$restrictions_date <- as.Date(restrictions_data$restrictions_date)
restrictions_data$quarantine_date <- as.Date(restrictions_data$quarantine_date)
main_data <- merge(main_data, restrictions_data[,c("country","population","tests","testpop","density",
"median_age","urbanpop","smokers", "sex_ratio",
"quarantine_date","restrictions_date",
"schools_national_date","schools_localized_date",
"hospital_bed","lung_disease")], by = c("country"), all.x = TRUE)
main_data <- main_data %>%
group_by(country) %>%
mutate(intervention_school_national = ifelse(date < schools_national_date,0,1)) %>%
mutate(intervention_school_local = ifelse(date < schools_localized_date,0,1)) %>%
mutate(intervention_restriction = ifelse(date < restrictions_date,0,1)) %>%
mutate(intervention_quarantine = ifelse(date < quarantine_date,0,1)) %>%
select(-c(schools_national_date,schools_localized_date,restrictions_date,quarantine_date))
data <- main_data
#TODO: add in features
data[, region:=paste(country, state)]
data[, first_case_date:=min(date[cases>0]), by=list(region)]
data[, case_days:=as.numeric(difftime(date, first_case_date,unit="days"))]
data[, log_case_days:=ifelse(case_days>0, log10(case_days), 0)]
data[, tenth_case_date:=min(date[cases>10]), by=list(region)]
data[, case10_days:=as.numeric(difftime(date, tenth_case_date,unit="days")), by=list(region)]
data[, hundreth_case_date:=min(date[cases>100]), by=list(region)]
data[, case100_days:=as.numeric(difftime(date, hundreth_case_date,unit="days")), by=list(region)]
data[, max_cases:=max(cases), by=list(region)]
covars <- colnames(data)[-which(names(data) %in% c("cases","region"))]
folds <- origami::make_folds(data, t = max(data$time), id = data$region,
time = data$time,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
library(devtools)
install_github("tlverse/origami@devel")
install_github("tlverse/origami@devel", force=TRUE)
load_all("tlversecovidforecast/")
main_data <- fread("Data/covid19-global-forecasting-week-1/train.csv")
old_names <- c("Id", "Province/State", "Country/Region", "Lat", "Long", "Date",
"ConfirmedCases", "Fatalities")
new_names <- c("id","state", "country", "lat", "long", "date", "cases", "deaths")
setnames(main_data, old_names, new_names)
main_data$date <- as.Date(main_data$date)
###TODO: merge in helper datasets
#1. Add intervention data (school, restrictions,quarantine)
#2. Add population, density, urban population, median age, sex info
#3. Add test and test population
#4. Add percent smokers and lung disease info
restrictions_data <- fread("Data/covid19-global-forecasting-week-1/restrictions_info_data.csv")
main_data$date <- as.Date(main_data$date)
restrictions_data$schools_national_date <- as.Date(restrictions_data$schools_national_date)
restrictions_data$schools_localized_date <- as.Date(restrictions_data$schools_localized_date)
restrictions_data$restrictions_date <- as.Date(restrictions_data$restrictions_date)
restrictions_data$quarantine_date <- as.Date(restrictions_data$quarantine_date)
main_data <- merge(main_data, restrictions_data[,c("country","population","tests","testpop","density",
"median_age","urbanpop","smokers", "sex_ratio",
"quarantine_date","restrictions_date",
"schools_national_date","schools_localized_date",
"hospital_bed","lung_disease")], by = c("country"), all.x = TRUE)
main_data <- main_data %>%
group_by(country) %>%
mutate(intervention_school_national = ifelse(date < schools_national_date,0,1)) %>%
mutate(intervention_school_local = ifelse(date < schools_localized_date,0,1)) %>%
mutate(intervention_restriction = ifelse(date < restrictions_date,0,1)) %>%
mutate(intervention_quarantine = ifelse(date < quarantine_date,0,1)) %>%
select(-c(schools_national_date,schools_localized_date,restrictions_date,quarantine_date))
data <- main_data
#TODO: add in features
data[, region:=paste(country, state)]
data[, first_case_date:=min(date[cases>0]), by=list(region)]
data[, case_days:=as.numeric(difftime(date, first_case_date,unit="days"))]
data[, log_case_days:=ifelse(case_days>0, log10(case_days), 0)]
data[, tenth_case_date:=min(date[cases>10]), by=list(region)]
data[, case10_days:=as.numeric(difftime(date, tenth_case_date,unit="days")), by=list(region)]
data[, hundreth_case_date:=min(date[cases>100]), by=list(region)]
data[, case100_days:=as.numeric(difftime(date, hundreth_case_date,unit="days")), by=list(region)]
data[, max_cases:=max(cases), by=list(region)]
return(data)
covars <- colnames(data)[-which(names(data) %in% c("cases","region"))]
folds <- origami::make_folds(data, t = max(data$time), id = data$region,
time = data$time,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
folds <- origami::make_folds(data, t = max(data$time), id = data$region,
time = data$date,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
folds <- origami::make_folds(data, t = max(data$date), id = data$region,
time = data$date,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
#TODO: add in features
data[, days:=min(date)]
folds <- origami::make_folds(data, t = max(data$day), id = data$region,
time = data$day,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
data$day
#TODO: add in features
data[, days:=as.numeric(difftime(date,min(date),unit="days"))]
folds <- origami::make_folds(data, t = max(data$day), id = data$region,
time = data$day,
fold_fun = folds_rolling_origin_pooled,
first_window = 30, validation_size = 30, gap = 0,
batch = 5)
folds <- origami::make_folds(data, t = max(data$day), id = data$region,
time = data$day,
fold_fun = folds_rolling_origin_pooled,
first_window = 20,
validation_size = 30,
gap = 0,
batch = 1)
# TODO: consider imputation of covariates, drop_missing_outcome
task <- make_sl3_Task(data, outcome = "cases", covariates = covariates,
folds = folds)
covariates <- colnames(data)[-which(names(data) %in% c("cases","region"))]
# TODO: consider imputation of covariates, drop_missing_outcome
task <- make_sl3_Task(data, outcome = "cases", covariates = covariates,
folds = folds)
#TODO integrate timeseries learners + mechanistic models
lrnr_glm <- make_learner(Lrnr_glm)
lrnr_rf <- make_learner(Lrnr_randomForest)
metalearner_competition <- make_learner(Lrnr_solnp, metalearner_linear_bound, loss_competition)
sl <- make_learner(Lrnr_sl, list(lrnr_glm, lrnr_rf), metalearner_competition)
fit <- sl$train(task)
#covariates <- colnames(data)[-which(names(data) %in% c("cases","region"))]
covariates <- c("case_days", "case100_days")
# TODO: consider imputation of covariates, drop_missing_outcome
task <- make_sl3_Task(data, outcome = "cases", covariates = covariates,
folds = folds)
fit <- sl$train(task)
task$X
str(data)
#covariates <- colnames(data)[-which(names(data) %in% c("cases","region"))]
covariates <- c("hospital_bed", "lung_disease")
# TODO: consider imputation of covariates, drop_missing_outcome
task <- make_sl3_Task(data, outcome = "cases", covariates = covariates,
folds = folds)
fit <- sl$train(task)
fit
table(data$country)
View(table(data$country))
quantile(data$cases)
table(data$cases==0)
